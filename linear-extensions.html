<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>16 Beyond Linear Regression | All Models Are Wrong</title>
  <meta name="description" content="This is a text about the fundamental concepts of Statistical Learning Methods." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="16 Beyond Linear Regression | All Models Are Wrong" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://allmodelsarewrong.github.io" />
  
  <meta property="og:description" content="This is a text about the fundamental concepts of Statistical Learning Methods." />
  <meta name="github-repo" content="allmodelsarewrong/allmodelsarewrong.github.io" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="16 Beyond Linear Regression | All Models Are Wrong" />
  
  <meta name="twitter:description" content="This is a text about the fundamental concepts of Statistical Learning Methods." />
  

<meta name="author" content="by Gaston Sanchez, and Ethan Marzban" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ridge.html"/>
<link rel="next" href="classif.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />











<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"><b>All Models Are Wrong (CSL)</b><br><small>by G. Sanchez & E. Marzban</small></a></li>

<li class="divider"></li>
<li class="part"><span><b>I Welcome</b></span></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="about.html"><a href="about.html"><i class="fa fa-check"></i><b>1</b> About this book</a><ul>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#prerequisites"><i class="fa fa-check"></i>Prerequisites</a></li>
<li class="chapter" data-level="" data-path="about.html"><a href="about.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="part"><span><b>II Intro</b></span></li>
<li class="chapter" data-level="2" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="intro.html"><a href="intro.html#basic-notation"><i class="fa fa-check"></i><b>2.1</b> Basic Notation</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="duality.html"><a href="duality.html"><i class="fa fa-check"></i><b>3</b> Geometric Duality</a><ul>
<li class="chapter" data-level="3.1" data-path="duality.html"><a href="duality.html#rows-space"><i class="fa fa-check"></i><b>3.1</b> Rows Space</a></li>
<li class="chapter" data-level="3.2" data-path="duality.html"><a href="duality.html#columns-space"><i class="fa fa-check"></i><b>3.2</b> Columns Space</a></li>
<li class="chapter" data-level="3.3" data-path="duality.html"><a href="duality.html#cloud-of-individuals"><i class="fa fa-check"></i><b>3.3</b> Cloud of Individuals</a><ul>
<li class="chapter" data-level="3.3.1" data-path="duality.html"><a href="duality.html#average-individual"><i class="fa fa-check"></i><b>3.3.1</b> Average Individual</a></li>
<li class="chapter" data-level="3.3.2" data-path="duality.html"><a href="duality.html#centered-data"><i class="fa fa-check"></i><b>3.3.2</b> Centered Data</a></li>
<li class="chapter" data-level="3.3.3" data-path="duality.html"><a href="duality.html#distance-between-individuals"><i class="fa fa-check"></i><b>3.3.3</b> Distance between individuals</a></li>
<li class="chapter" data-level="3.3.4" data-path="duality.html"><a href="duality.html#distance-to-the-centroid"><i class="fa fa-check"></i><b>3.3.4</b> Distance to the centroid</a></li>
<li class="chapter" data-level="3.3.5" data-path="duality.html"><a href="duality.html#measures-of-dispersion"><i class="fa fa-check"></i><b>3.3.5</b> Measures of Dispersion</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="duality.html"><a href="duality.html#cloud-of-variables"><i class="fa fa-check"></i><b>3.4</b> Cloud of Variables</a><ul>
<li class="chapter" data-level="3.4.1" data-path="duality.html"><a href="duality.html#mean-of-a-variable"><i class="fa fa-check"></i><b>3.4.1</b> Mean of a Variable</a></li>
<li class="chapter" data-level="3.4.2" data-path="duality.html"><a href="duality.html#variance-of-a-variable"><i class="fa fa-check"></i><b>3.4.2</b> Variance of a Variable</a></li>
<li class="chapter" data-level="3.4.3" data-path="duality.html"><a href="duality.html#variance-with-vector-notation"><i class="fa fa-check"></i><b>3.4.3</b> Variance with Vector Notation</a></li>
<li class="chapter" data-level="3.4.4" data-path="duality.html"><a href="duality.html#standard-deviation-as-a-norm"><i class="fa fa-check"></i><b>3.4.4</b> Standard Deviation as a Norm</a></li>
<li class="chapter" data-level="3.4.5" data-path="duality.html"><a href="duality.html#covariance"><i class="fa fa-check"></i><b>3.4.5</b> Covariance</a></li>
<li class="chapter" data-level="3.4.6" data-path="duality.html"><a href="duality.html#correlation"><i class="fa fa-check"></i><b>3.4.6</b> Correlation</a></li>
<li class="chapter" data-level="3.4.7" data-path="duality.html"><a href="duality.html#geometry-of-correlation"><i class="fa fa-check"></i><b>3.4.7</b> Geometry of Correlation</a></li>
<li class="chapter" data-level="3.4.8" data-path="duality.html"><a href="duality.html#orthogonal-projections"><i class="fa fa-check"></i><b>3.4.8</b> Orthogonal Projections</a></li>
<li class="chapter" data-level="3.4.9" data-path="duality.html"><a href="duality.html#the-mean-as-an-orthogonal-projection"><i class="fa fa-check"></i><b>3.4.9</b> The mean as an orthogonal projection</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Unsupervised I: PCA</b></span></li>
<li class="chapter" data-level="4" data-path="pca.html"><a href="pca.html"><i class="fa fa-check"></i><b>4</b> Principal Components Analysis</a><ul>
<li class="chapter" data-level="4.1" data-path="pca.html"><a href="pca.html#low-dimensional-representations"><i class="fa fa-check"></i><b>4.1</b> Low-dimensional Representations</a></li>
<li class="chapter" data-level="4.2" data-path="pca.html"><a href="pca.html#projections"><i class="fa fa-check"></i><b>4.2</b> Projections</a><ul>
<li class="chapter" data-level="4.2.1" data-path="pca.html"><a href="pca.html#vector-and-scalar-projections"><i class="fa fa-check"></i><b>4.2.1</b> Vector and Scalar Projections</a></li>
<li class="chapter" data-level="4.2.2" data-path="pca.html"><a href="pca.html#projected-inertia"><i class="fa fa-check"></i><b>4.2.2</b> Projected Inertia</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="pca.html"><a href="pca.html#maximization-problem"><i class="fa fa-check"></i><b>4.3</b> Maximization Problem</a><ul>
<li class="chapter" data-level="4.3.1" data-path="pca.html"><a href="pca.html#eigenvectors-of-mathbfs"><i class="fa fa-check"></i><b>4.3.1</b> Eigenvectors of <span class="math inline">\(\mathbf{S}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="pca.html"><a href="pca.html#another-perspective-of-pca"><i class="fa fa-check"></i><b>4.4</b> Another Perspective of PCA</a><ul>
<li class="chapter" data-level="4.4.1" data-path="pca.html"><a href="pca.html#finding-principal-components"><i class="fa fa-check"></i><b>4.4.1</b> Finding Principal Components</a></li>
<li class="chapter" data-level="4.4.2" data-path="pca.html"><a href="pca.html#finding-the-first-pc"><i class="fa fa-check"></i><b>4.4.2</b> Finding the first PC</a></li>
<li class="chapter" data-level="4.4.3" data-path="pca.html"><a href="pca.html#finding-the-second-pc"><i class="fa fa-check"></i><b>4.4.3</b> Finding the second PC</a></li>
<li class="chapter" data-level="4.4.4" data-path="pca.html"><a href="pca.html#finding-all-pcs"><i class="fa fa-check"></i><b>4.4.4</b> Finding all PCs</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="pca.html"><a href="pca.html#data-decomposition-model"><i class="fa fa-check"></i><b>4.5</b> Data Decomposition Model</a><ul>
<li class="chapter" data-level="4.5.1" data-path="pca.html"><a href="pca.html#alternative-approaches"><i class="fa fa-check"></i><b>4.5.1</b> Alternative Approaches</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Linear Regression</b></span></li>
<li class="chapter" data-level="5" data-path="ols.html"><a href="ols.html"><i class="fa fa-check"></i><b>5</b> Linear Regression</a><ul>
<li class="chapter" data-level="5.1" data-path="ols.html"><a href="ols.html#motivation"><i class="fa fa-check"></i><b>5.1</b> Motivation</a></li>
<li class="chapter" data-level="5.2" data-path="ols.html"><a href="ols.html#the-ideaintuition-of-regression"><i class="fa fa-check"></i><b>5.2</b> The Idea/Intuition of Regression</a></li>
<li class="chapter" data-level="5.3" data-path="ols.html"><a href="ols.html#the-linear-regression-model"><i class="fa fa-check"></i><b>5.3</b> The Linear Regression Model</a></li>
<li class="chapter" data-level="5.4" data-path="ols.html"><a href="ols.html#the-error-measure"><i class="fa fa-check"></i><b>5.4</b> The Error Measure</a></li>
<li class="chapter" data-level="5.5" data-path="ols.html"><a href="ols.html#the-least-squares-algorithm"><i class="fa fa-check"></i><b>5.5</b> The Least Squares Algorithm</a></li>
<li class="chapter" data-level="5.6" data-path="ols.html"><a href="ols.html#geometries-of-ols"><i class="fa fa-check"></i><b>5.6</b> Geometries of OLS</a><ul>
<li class="chapter" data-level="5.6.1" data-path="ols.html"><a href="ols.html#rows-perspective"><i class="fa fa-check"></i><b>5.6.1</b> Rows Perspective</a></li>
<li class="chapter" data-level="5.6.2" data-path="ols.html"><a href="ols.html#columns-perspective"><i class="fa fa-check"></i><b>5.6.2</b> Columns Perspective</a></li>
<li class="chapter" data-level="5.6.3" data-path="ols.html"><a href="ols.html#parameters-perspective"><i class="fa fa-check"></i><b>5.6.3</b> Parameters Perspective</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="gradient.html"><a href="gradient.html"><i class="fa fa-check"></i><b>6</b> Gradient Descent</a><ul>
<li class="chapter" data-level="6.1" data-path="gradient.html"><a href="gradient.html#error-surface"><i class="fa fa-check"></i><b>6.1</b> Error Surface</a></li>
<li class="chapter" data-level="6.2" data-path="gradient.html"><a href="gradient.html#idea-of-gradient-descent"><i class="fa fa-check"></i><b>6.2</b> Idea of Gradient Descent</a></li>
<li class="chapter" data-level="6.3" data-path="gradient.html"><a href="gradient.html#moving-down-an-error-surface"><i class="fa fa-check"></i><b>6.3</b> Moving Down an Error Surface</a><ul>
<li class="chapter" data-level="6.3.1" data-path="gradient.html"><a href="gradient.html#the-direction-of-mathbfv"><i class="fa fa-check"></i><b>6.3.1</b> The direction of <span class="math inline">\(\mathbf{v}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="gradient.html"><a href="gradient.html#gradient-descent-and-our-model"><i class="fa fa-check"></i><b>6.4</b> Gradient Descent and our Model</a></li>
</ul></li>
<li class="part"><span><b>V Learning Concepts</b></span></li>
<li class="chapter" data-level="7" data-path="learning.html"><a href="learning.html"><i class="fa fa-check"></i><b>7</b> Theoretical Framework</a><ul>
<li class="chapter" data-level="7.1" data-path="learning.html"><a href="learning.html#mental-map"><i class="fa fa-check"></i><b>7.1</b> Mental Map</a></li>
<li class="chapter" data-level="7.2" data-path="learning.html"><a href="learning.html#kinds-of-predictions"><i class="fa fa-check"></i><b>7.2</b> Kinds of Predictions</a><ul>
<li class="chapter" data-level="7.2.1" data-path="learning.html"><a href="learning.html#two-types-of-data"><i class="fa fa-check"></i><b>7.2.1</b> Two Types of Data</a></li>
<li class="chapter" data-level="7.2.2" data-path="learning.html"><a href="learning.html#two-types-of-predictions"><i class="fa fa-check"></i><b>7.2.2</b> Two Types of Predictions</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="learning.html"><a href="learning.html#two-types-of-errors"><i class="fa fa-check"></i><b>7.3</b> Two Types of Errors</a><ul>
<li class="chapter" data-level="7.3.1" data-path="learning.html"><a href="learning.html#individual-errors"><i class="fa fa-check"></i><b>7.3.1</b> Individual Errors</a></li>
<li class="chapter" data-level="7.3.2" data-path="learning.html"><a href="learning.html#overall-errors"><i class="fa fa-check"></i><b>7.3.2</b> Overall Errors</a></li>
<li class="chapter" data-level="7.3.3" data-path="learning.html"><a href="learning.html#auxiliary-technicality"><i class="fa fa-check"></i><b>7.3.3</b> Auxiliary Technicality</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="learning.html"><a href="learning.html#noisy-targets"><i class="fa fa-check"></i><b>7.4</b> Noisy Targets</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="mse.html"><a href="mse.html"><i class="fa fa-check"></i><b>8</b> MSE of Estimator</a><ul>
<li class="chapter" data-level="8.1" data-path="mse.html"><a href="mse.html#mse-of-an-estimator"><i class="fa fa-check"></i><b>8.1</b> MSE of an Estimator</a><ul>
<li class="chapter" data-level="8.1.1" data-path="mse.html"><a href="mse.html#prototypical-cases-of-bias-and-variance"><i class="fa fa-check"></i><b>8.1.1</b> Prototypical Cases of Bias and Variance</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="biasvar.html"><a href="biasvar.html"><i class="fa fa-check"></i><b>9</b> Bias-Variance Tradeoff</a><ul>
<li class="chapter" data-level="9.1" data-path="biasvar.html"><a href="biasvar.html#introduction"><i class="fa fa-check"></i><b>9.1</b> Introduction</a></li>
<li class="chapter" data-level="9.2" data-path="biasvar.html"><a href="biasvar.html#motivation-example"><i class="fa fa-check"></i><b>9.2</b> Motivation Example</a><ul>
<li class="chapter" data-level="9.2.1" data-path="biasvar.html"><a href="biasvar.html#two-hypotheses"><i class="fa fa-check"></i><b>9.2.1</b> Two Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="biasvar.html"><a href="biasvar.html#learning-from-two-points"><i class="fa fa-check"></i><b>9.3</b> Learning from two points</a></li>
<li class="chapter" data-level="9.4" data-path="biasvar.html"><a href="biasvar.html#bias-variance-derivation"><i class="fa fa-check"></i><b>9.4</b> Bias-Variance Derivation</a><ul>
<li class="chapter" data-level="9.4.1" data-path="biasvar.html"><a href="biasvar.html#out-of-sample-predictions"><i class="fa fa-check"></i><b>9.4.1</b> Out-of-Sample Predictions</a></li>
<li class="chapter" data-level="9.4.2" data-path="biasvar.html"><a href="biasvar.html#noisy-target"><i class="fa fa-check"></i><b>9.4.2</b> Noisy Target</a></li>
<li class="chapter" data-level="9.4.3" data-path="biasvar.html"><a href="biasvar.html#types-of-theoretical-mses"><i class="fa fa-check"></i><b>9.4.3</b> Types of Theoretical MSEs</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="biasvar.html"><a href="biasvar.html#the-tradeoff"><i class="fa fa-check"></i><b>9.5</b> The Tradeoff</a><ul>
<li class="chapter" data-level="9.5.1" data-path="biasvar.html"><a href="biasvar.html#bias-variance-tradeoff-picture"><i class="fa fa-check"></i><b>9.5.1</b> Bias-Variance Tradeoff Picture</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="phases.html"><a href="phases.html"><i class="fa fa-check"></i><b>10</b> Learning Phases</a><ul>
<li class="chapter" data-level="10.1" data-path="phases.html"><a href="phases.html#introduction-1"><i class="fa fa-check"></i><b>10.1</b> Introduction</a></li>
<li class="chapter" data-level="10.2" data-path="phases.html"><a href="phases.html#model-assessment"><i class="fa fa-check"></i><b>10.2</b> Model Assessment</a><ul>
<li class="chapter" data-level="10.2.1" data-path="phases.html"><a href="phases.html#holdout-test-set"><i class="fa fa-check"></i><b>10.2.1</b> Holdout Test Set</a></li>
<li class="chapter" data-level="10.2.2" data-path="phases.html"><a href="phases.html#why-does-a-test-set-work"><i class="fa fa-check"></i><b>10.2.2</b> Why does a test set work?</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="phases.html"><a href="phases.html#model-selection"><i class="fa fa-check"></i><b>10.3</b> Model Selection</a><ul>
<li class="chapter" data-level="10.3.1" data-path="phases.html"><a href="phases.html#three-way-holdout-method"><i class="fa fa-check"></i><b>10.3.1</b> Three-way Holdout Method</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="phases.html"><a href="phases.html#model-training"><i class="fa fa-check"></i><b>10.4</b> Model Training</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="resampling.html"><a href="resampling.html"><i class="fa fa-check"></i><b>11</b> Resample Approaches</a><ul>
<li class="chapter" data-level="11.1" data-path="resampling.html"><a href="resampling.html#general-sampling-blueprint"><i class="fa fa-check"></i><b>11.1</b> General Sampling Blueprint</a></li>
<li class="chapter" data-level="11.2" data-path="resampling.html"><a href="resampling.html#monte-carlo-cross-validation"><i class="fa fa-check"></i><b>11.2</b> Monte Carlo Cross Validation</a></li>
<li class="chapter" data-level="11.3" data-path="resampling.html"><a href="resampling.html#bootstrap-method"><i class="fa fa-check"></i><b>11.3</b> Bootstrap Method</a></li>
<li class="chapter" data-level="11.4" data-path="resampling.html"><a href="resampling.html#k-fold-cross-validation"><i class="fa fa-check"></i><b>11.4</b> <span class="math inline">\(K\)</span>-Fold Cross-Validation</a><ul>
<li class="chapter" data-level="11.4.1" data-path="resampling.html"><a href="resampling.html#leave-one-out-cross-validation-loocv"><i class="fa fa-check"></i><b>11.4.1</b> Leave-One-Out Cross Validation (LOOCV)</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VI Regularization</b></span></li>
<li class="chapter" data-level="12" data-path="regular.html"><a href="regular.html"><i class="fa fa-check"></i><b>12</b> Regularization Techniques</a><ul>
<li class="chapter" data-level="12.1" data-path="regular.html"><a href="regular.html#multicollinearity-issues"><i class="fa fa-check"></i><b>12.1</b> Multicollinearity Issues</a><ul>
<li class="chapter" data-level="12.1.1" data-path="regular.html"><a href="regular.html#toy-example"><i class="fa fa-check"></i><b>12.1.1</b> Toy Example</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="regular.html"><a href="regular.html#irregular-coefficients"><i class="fa fa-check"></i><b>12.2</b> Irregular Coefficients</a></li>
<li class="chapter" data-level="12.3" data-path="regular.html"><a href="regular.html#connection-to-regularization"><i class="fa fa-check"></i><b>12.3</b> Connection to Regularization</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="pcr.html"><a href="pcr.html"><i class="fa fa-check"></i><b>13</b> Principal Components Regression</a><ul>
<li class="chapter" data-level="13.1" data-path="pcr.html"><a href="pcr.html#motivation-example-1"><i class="fa fa-check"></i><b>13.1</b> Motivation Example</a></li>
<li class="chapter" data-level="13.2" data-path="pcr.html"><a href="pcr.html#the-pcr-model"><i class="fa fa-check"></i><b>13.2</b> The PCR Model</a></li>
<li class="chapter" data-level="13.3" data-path="pcr.html"><a href="pcr.html#how-does-pcr-work"><i class="fa fa-check"></i><b>13.3</b> How does PCR work?</a><ul>
<li class="chapter" data-level="13.3.1" data-path="pcr.html"><a href="pcr.html#transition-formula"><i class="fa fa-check"></i><b>13.3.1</b> Transition Formula</a></li>
<li class="chapter" data-level="13.3.2" data-path="pcr.html"><a href="pcr.html#size-of-coefficients"><i class="fa fa-check"></i><b>13.3.2</b> Size of Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="pcr.html"><a href="pcr.html#selecting-number-of-pcs"><i class="fa fa-check"></i><b>13.4</b> Selecting Number of PCs</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="pls.html"><a href="pls.html"><i class="fa fa-check"></i><b>14</b> Partial Least Squares Regression</a><ul>
<li class="chapter" data-level="14.1" data-path="pls.html"><a href="pls.html#motivation-example-2"><i class="fa fa-check"></i><b>14.1</b> Motivation Example</a></li>
<li class="chapter" data-level="14.2" data-path="pls.html"><a href="pls.html#the-plsr-model"><i class="fa fa-check"></i><b>14.2</b> The PLSR Model</a></li>
<li class="chapter" data-level="14.3" data-path="pls.html"><a href="pls.html#how-does-plsr-work"><i class="fa fa-check"></i><b>14.3</b> How does PLSR work?</a></li>
<li class="chapter" data-level="14.4" data-path="pls.html"><a href="pls.html#plsr-algorithm"><i class="fa fa-check"></i><b>14.4</b> PLSR Algorithm</a><ul>
<li class="chapter" data-level="14.4.1" data-path="pls.html"><a href="pls.html#pls-solution-with-original-variables"><i class="fa fa-check"></i><b>14.4.1</b> PLS Solution with original variables</a></li>
<li class="chapter" data-level="14.4.2" data-path="pls.html"><a href="pls.html#size-of-coefficients-1"><i class="fa fa-check"></i><b>14.4.2</b> Size of Coefficients</a></li>
<li class="chapter" data-level="14.4.3" data-path="pls.html"><a href="pls.html#some-properties"><i class="fa fa-check"></i><b>14.4.3</b> Some Properties</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="pls.html"><a href="pls.html#selecting-number-of-pls-components"><i class="fa fa-check"></i><b>14.5</b> Selecting Number of PLS Components</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="ridge.html"><a href="ridge.html"><i class="fa fa-check"></i><b>15</b> Ridge Regression</a><ul>
<li class="chapter" data-level="15.1" data-path="ridge.html"><a href="ridge.html#a-new-minimization-problem"><i class="fa fa-check"></i><b>15.1</b> A New Minimization Problem</a><ul>
<li class="chapter" data-level="15.1.1" data-path="ridge.html"><a href="ridge.html#constraining-regression-coefficients"><i class="fa fa-check"></i><b>15.1.1</b> Constraining Regression Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="ridge.html"><a href="ridge.html#a-new-minimization-solution"><i class="fa fa-check"></i><b>15.2</b> A New Minimization Solution</a></li>
</ul></li>
<li class="part"><span><b>VII Extending Linear Regression</b></span></li>
<li class="chapter" data-level="16" data-path="linear-extensions.html"><a href="linear-extensions.html"><i class="fa fa-check"></i><b>16</b> Beyond Linear Regression</a><ul>
<li class="chapter" data-level="16.1" data-path="linear-extensions.html"><a href="linear-extensions.html#introduction-2"><i class="fa fa-check"></i><b>16.1</b> Introduction</a><ul>
<li class="chapter" data-level="16.1.1" data-path="linear-extensions.html"><a href="linear-extensions.html#expanding-the-regression-horizon"><i class="fa fa-check"></i><b>16.1.1</b> Expanding the Regression Horizon</a></li>
</ul></li>
<li class="chapter" data-level="16.2" data-path="linear-extensions.html"><a href="linear-extensions.html#transforming-features"><i class="fa fa-check"></i><b>16.2</b> Transforming Features</a></li>
</ul></li>
<li class="part"><span><b>VIII Classification</b></span></li>
<li class="chapter" data-level="17" data-path="classif.html"><a href="classif.html"><i class="fa fa-check"></i><b>17</b> Classification Methods</a></li>
<li class="chapter" data-level="18" data-path="logistic.html"><a href="logistic.html"><i class="fa fa-check"></i><b>18</b> Logistic Regression</a><ul>
<li class="chapter" data-level="18.1" data-path="logistic.html"><a href="logistic.html#motivation-1"><i class="fa fa-check"></i><b>18.1</b> Motivation</a><ul>
<li class="chapter" data-level="18.1.1" data-path="logistic.html"><a href="logistic.html#first-approach-fitting-a-line"><i class="fa fa-check"></i><b>18.1.1</b> First Approach: Fitting a Line</a></li>
<li class="chapter" data-level="18.1.2" data-path="logistic.html"><a href="logistic.html#secodn-approach-harsh-thresholding"><i class="fa fa-check"></i><b>18.1.2</b> Secodn Approach: Harsh Thresholding</a></li>
<li class="chapter" data-level="18.1.3" data-path="logistic.html"><a href="logistic.html#third-approach-conditional-means"><i class="fa fa-check"></i><b>18.1.3</b> Third Approach: Conditional Means</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="logistic.html"><a href="logistic.html#logistic-regression-model"><i class="fa fa-check"></i><b>18.2</b> Logistic Regression Model</a><ul>
<li class="chapter" data-level="18.2.1" data-path="logistic.html"><a href="logistic.html#the-criterion-being-optimized"><i class="fa fa-check"></i><b>18.2.1</b> The Criterion Being Optimized</a></li>
<li class="chapter" data-level="18.2.2" data-path="logistic.html"><a href="logistic.html#another-way-to-solve-logistic-regression"><i class="fa fa-check"></i><b>18.2.2</b> Another Way to Solve Logistic Regression</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="discrim.html"><a href="discrim.html"><i class="fa fa-check"></i><b>19</b> Preamble for Discriminant Analysis</a><ul>
<li class="chapter" data-level="19.1" data-path="discrim.html"><a href="discrim.html#motivation-2"><i class="fa fa-check"></i><b>19.1</b> Motivation</a><ul>
<li class="chapter" data-level="19.1.1" data-path="discrim.html"><a href="discrim.html#distinguishing-species"><i class="fa fa-check"></i><b>19.1.1</b> Distinguishing Species</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="discrim.html"><a href="discrim.html#derived-ratios-from-sum-of-squares"><i class="fa fa-check"></i><b>19.2</b> Derived Ratios from Sum-of-Squares</a><ul>
<li class="chapter" data-level="19.2.1" data-path="discrim.html"><a href="discrim.html#correlation-ratio"><i class="fa fa-check"></i><b>19.2.1</b> Correlation Ratio</a></li>
<li class="chapter" data-level="19.2.2" data-path="discrim.html"><a href="discrim.html#f-ratio"><i class="fa fa-check"></i><b>19.2.2</b> F-Ratio</a></li>
<li class="chapter" data-level="19.2.3" data-path="discrim.html"><a href="discrim.html#example-with-iris-data"><i class="fa fa-check"></i><b>19.2.3</b> Example with Iris data</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="discrim.html"><a href="discrim.html#geometric-perspective"><i class="fa fa-check"></i><b>19.3</b> Geometric Perspective</a><ul>
<li class="chapter" data-level="19.3.1" data-path="discrim.html"><a href="discrim.html#clouds-from-class-structure"><i class="fa fa-check"></i><b>19.3.1</b> Clouds from Class Structure</a></li>
<li class="chapter" data-level="19.3.2" data-path="discrim.html"><a href="discrim.html#dispersion-decomposition"><i class="fa fa-check"></i><b>19.3.2</b> Dispersion Decomposition</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="cda.html"><a href="cda.html"><i class="fa fa-check"></i><b>20</b> Canonical Discriminant Analysis</a><ul>
<li class="chapter" data-level="20.0.1" data-path="cda.html"><a href="cda.html#looking-for-a-discriminant-axis"><i class="fa fa-check"></i><b>20.0.1</b> Looking for a discriminant axis</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="discanalysis.html"><a href="discanalysis.html"><i class="fa fa-check"></i><b>21</b> Discriminant Analysis</a><ul>
<li class="chapter" data-level="21.1" data-path="discanalysis.html"><a href="discanalysis.html#probabilistic-da"><i class="fa fa-check"></i><b>21.1</b> Probabilistic DA</a></li>
<li class="chapter" data-level="21.2" data-path="discanalysis.html"><a href="discanalysis.html#estimations"><i class="fa fa-check"></i><b>21.2</b> Estimations</a><ul>
<li class="chapter" data-level="21.2.1" data-path="discanalysis.html"><a href="discanalysis.html#univariate-data-boldsymbolp-1"><i class="fa fa-check"></i><b>21.2.1</b> Univariate Data (<span class="math inline">\(\boldsymbol{p = 1}\)</span>)</a></li>
<li class="chapter" data-level="21.2.2" data-path="discanalysis.html"><a href="discanalysis.html#multivariate-data-boldsymbolp-1"><i class="fa fa-check"></i><b>21.2.2</b> Multivariate Data (<span class="math inline">\(\boldsymbol{p &gt; 1}\)</span>)</a></li>
<li class="chapter" data-level="21.2.3" data-path="discanalysis.html"><a href="discanalysis.html#multivariate-estimations"><i class="fa fa-check"></i><b>21.2.3</b> Multivariate Estimations</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="discanalysis.html"><a href="discanalysis.html#discriminant-functions"><i class="fa fa-check"></i><b>21.3</b> Discriminant Functions</a></li>
<li class="chapter" data-level="21.4" data-path="discanalysis.html"><a href="discanalysis.html#quadratic-discriminant-analysis-qda"><i class="fa fa-check"></i><b>21.4</b> Quadratic Discriminant Analysis (QDA)</a></li>
<li class="chapter" data-level="21.5" data-path="discanalysis.html"><a href="discanalysis.html#linear-discriminant-analysis"><i class="fa fa-check"></i><b>21.5</b> Linear Discriminant Analysis</a></li>
<li class="chapter" data-level="21.6" data-path="discanalysis.html"><a href="discanalysis.html#canonical-discriminant-analysis"><i class="fa fa-check"></i><b>21.6</b> Canonical Discriminant Analysis</a></li>
<li class="chapter" data-level="21.7" data-path="discanalysis.html"><a href="discanalysis.html#naive-bayes"><i class="fa fa-check"></i><b>21.7</b> Naive Bayes</a></li>
<li class="chapter" data-level="21.8" data-path="discanalysis.html"><a href="discanalysis.html#fifth-case"><i class="fa fa-check"></i><b>21.8</b> Fifth Case</a></li>
<li class="chapter" data-level="21.9" data-path="discanalysis.html"><a href="discanalysis.html#comparing-the-cases"><i class="fa fa-check"></i><b>21.9</b> Comparing the Cases</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="classperformance.html"><a href="classperformance.html"><i class="fa fa-check"></i><b>22</b> Performance of Classifiers</a><ul>
<li class="chapter" data-level="22.1" data-path="classperformance.html"><a href="classperformance.html#error-for-binary-response"><i class="fa fa-check"></i><b>22.1</b> Error for Binary Response</a></li>
<li class="chapter" data-level="22.2" data-path="classperformance.html"><a href="classperformance.html#categorical-response"><i class="fa fa-check"></i><b>22.2</b> Categorical Response</a></li>
<li class="chapter" data-level="22.3" data-path="classperformance.html"><a href="classperformance.html#confusion-matrices"><i class="fa fa-check"></i><b>22.3</b> Confusion Matrices</a></li>
<li class="chapter" data-level="22.4" data-path="classperformance.html"><a href="classperformance.html#binary-response-example"><i class="fa fa-check"></i><b>22.4</b> Binary Response: Example</a><ul>
<li class="chapter" data-level="22.4.1" data-path="classperformance.html"><a href="classperformance.html#types-of-errors-application-for-savings-account"><i class="fa fa-check"></i><b>22.4.1</b> Types of Errors: Application for Savings Account</a></li>
<li class="chapter" data-level="22.4.2" data-path="classperformance.html"><a href="classperformance.html#another-example-loans"><i class="fa fa-check"></i><b>22.4.2</b> Another Example: Loans</a></li>
<li class="chapter" data-level="22.4.3" data-path="classperformance.html"><a href="classperformance.html#the-ideal-situation"><i class="fa fa-check"></i><b>22.4.3</b> The Ideal Situation</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IX Unsupervised II: Clustering</b></span></li>
<li class="chapter" data-level="23" data-path="clustering.html"><a href="clustering.html"><i class="fa fa-check"></i><b>23</b> Clustering</a><ul>
<li class="chapter" data-level="23.1" data-path="clustering.html"><a href="clustering.html#about-clustering"><i class="fa fa-check"></i><b>23.1</b> About Clustering</a><ul>
<li class="chapter" data-level="23.1.1" data-path="clustering.html"><a href="clustering.html#types-of-clustering"><i class="fa fa-check"></i><b>23.1.1</b> Types of Clustering</a></li>
<li class="chapter" data-level="23.1.2" data-path="clustering.html"><a href="clustering.html#hard-clustering"><i class="fa fa-check"></i><b>23.1.2</b> Hard Clustering</a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="clustering.html"><a href="clustering.html#dispersion-measures"><i class="fa fa-check"></i><b>23.2</b> Dispersion Measures</a></li>
<li class="chapter" data-level="23.3" data-path="clustering.html"><a href="clustering.html#complexity-in-clustering"><i class="fa fa-check"></i><b>23.3</b> Complexity in Clustering</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="kmeans.html"><a href="kmeans.html"><i class="fa fa-check"></i><b>24</b> K-Means</a><ul>
<li class="chapter" data-level="24.1" data-path="kmeans.html"><a href="kmeans.html#toy-example-1"><i class="fa fa-check"></i><b>24.1</b> Toy Example</a></li>
<li class="chapter" data-level="24.2" data-path="kmeans.html"><a href="kmeans.html#what-does-k-means-do"><i class="fa fa-check"></i><b>24.2</b> What does K-means do?</a></li>
<li class="chapter" data-level="24.3" data-path="kmeans.html"><a href="kmeans.html#k-means-algorithms"><i class="fa fa-check"></i><b>24.3</b> K-Means Algorithms</a><ul>
<li class="chapter" data-level="24.3.1" data-path="kmeans.html"><a href="kmeans.html#classic-version"><i class="fa fa-check"></i><b>24.3.1</b> Classic Version</a></li>
<li class="chapter" data-level="24.3.2" data-path="kmeans.html"><a href="kmeans.html#moving-centers-algorithm"><i class="fa fa-check"></i><b>24.3.2</b> Moving Centers Algorithm</a></li>
<li class="chapter" data-level="24.3.3" data-path="kmeans.html"><a href="kmeans.html#dynamic-clouds"><i class="fa fa-check"></i><b>24.3.3</b> Dynamic Clouds</a></li>
<li class="chapter" data-level="24.3.4" data-path="kmeans.html"><a href="kmeans.html#choosing-k"><i class="fa fa-check"></i><b>24.3.4</b> Choosing <span class="math inline">\(k\)</span></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="hclus.html"><a href="hclus.html"><i class="fa fa-check"></i><b>25</b> Hierarchical Clustering</a><ul>
<li class="chapter" data-level="25.1" data-path="hclus.html"><a href="hclus.html#agglomerative-methods"><i class="fa fa-check"></i><b>25.1</b> Agglomerative Methods</a></li>
<li class="chapter" data-level="25.2" data-path="hclus.html"><a href="hclus.html#example-single-linkage"><i class="fa fa-check"></i><b>25.2</b> Example: Single Linkage</a><ul>
<li class="chapter" data-level="25.2.1" data-path="hclus.html"><a href="hclus.html#dendrogram"><i class="fa fa-check"></i><b>25.2.1</b> Dendrogram</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>X Tree-based Methods</b></span></li>
<li class="chapter" data-level="26" data-path="trees.html"><a href="trees.html"><i class="fa fa-check"></i><b>26</b> Intro to Decision Trees</a><ul>
<li class="chapter" data-level="26.1" data-path="trees.html"><a href="trees.html#introduction-3"><i class="fa fa-check"></i><b>26.1</b> Introduction</a></li>
<li class="chapter" data-level="26.2" data-path="trees.html"><a href="trees.html#binary-trees"><i class="fa fa-check"></i><b>26.2</b> Binary Trees</a><ul>
<li class="chapter" data-level="26.2.1" data-path="trees.html"><a href="trees.html#the-process-of-building-a-tree"><i class="fa fa-check"></i><b>26.2.1</b> The Process of Building a Tree</a></li>
<li class="chapter" data-level="26.2.2" data-path="trees.html"><a href="trees.html#binary-partitions"><i class="fa fa-check"></i><b>26.2.2</b> Binary Partitions</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="trees.html"><a href="trees.html#measures-of-heterogeneity"><i class="fa fa-check"></i><b>26.3</b> Measures of Heterogeneity</a><ul>
<li class="chapter" data-level="26.3.1" data-path="trees.html"><a href="trees.html#entropy"><i class="fa fa-check"></i><b>26.3.1</b> Entropy</a></li>
<li class="chapter" data-level="26.3.2" data-path="trees.html"><a href="trees.html#the-math-behind-entropy"><i class="fa fa-check"></i><b>26.3.2</b> The Math Behind Entropy</a></li>
<li class="chapter" data-level="26.3.3" data-path="trees.html"><a href="trees.html#gini-impurity"><i class="fa fa-check"></i><b>26.3.3</b> Gini Impurity</a></li>
<li class="chapter" data-level="26.3.4" data-path="trees.html"><a href="trees.html#toy-example-2"><i class="fa fa-check"></i><b>26.3.4</b> Toy Example</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Made with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">All Models Are Wrong</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="linear-extensions" class="section level1">
<h1><span class="header-section-number">16</span> Beyond Linear Regression</h1>
<p>In this part of the book we will talk about extensions of the linear model,
as well as alternative approaches to relax the assumption of linearity.</p>
<div id="introduction-2" class="section level2">
<h2><span class="header-section-number">16.1</span> Introduction</h2>
<p>So far we have talked about regression models in their most basic way: linear
regression models. So let’s circle back to the general regression
framework in which the main idea is to find a function <span class="math inline">\(f()\)</span> that takes in one
or more input features, and returns a response value. In addition, we also
suppose that there is a noise or error term to indicate the imperfect nature
of our model:</p>
<p><span class="math display">\[
y_i = f(\mathbf{x_i}) + \varepsilon_i
\]</span></p>
<p>Usually, we assume that the error terms have zero-men:
<span class="math inline">\(\mathbb{E}(\varepsilon_i) = 0\)</span>, and constant variance:
<span class="math inline">\(var(\varepsilon_i) = \sigma^2\)</span>.</p>
<p>The theoretical essence in regression is to model <span class="math inline">\(f()\)</span> as the conditional
expectation of <span class="math inline">\(y|\mathbf{x}\)</span>, which is precisely the so-called
<strong>regresion function</strong>:</p>
<p><span class="math display">\[
\text{regression function} \longrightarrow \mathbb{E} (y|\mathbf{x}) = f(\mathbf{x})
\]</span></p>
<p>One important thing to highlight is that the theoretical framework of regression
says nothing about what the target function <span class="math inline">\(f()\)</span> should or could look like,
which is good news because we have a lot of freedom to decide on almost any
form for <span class="math inline">\(f()\)</span>. Again, here the term <em>function</em> is not the classic definition
of a mathematical function. Instead, think of the notion of function as a
machine that takes inputs <span class="math inline">\(\mathbf{x}\)</span>, and returns an output.</p>
<p>Up to now we have been working with the most standard type of form for <span class="math inline">\(f()\)</span>
which is a linear model:</p>
<p><span class="math display">\[
\hat{y}_i = b_0 + b_1 x_{i1} + b_2 x_{i2} + \dots + b_p x_{ip} = \mathbf{b^\mathsf{T} x_i}
\]</span></p>
<p>or its equivalent formula in vector-matrix notation:</p>
<p><span class="math display">\[
\mathbf{\hat{y}} = \mathbf{Xb}
\]</span></p>
<p>which we can graphically represent using a path diagram like this (assuming
a cosntant term <span class="math inline">\(\mathbf{x_0} = \mathbf{1}\)</span>):</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-161"></span>
<img src="images/ols/ols-path-diagram-betas0.svg" alt="Linear regression model in diagram form" width="40%" />
<p class="caption">
Figure 16.1: Linear regression model in diagram form
</p>
</div>
<p>While a linear regression model like the one above is important, and can be
used as a good starting point, is far too limiting. Therefore, we need to
discuss some of the ways in which the standard linear regression model can be
enriched and be made more flexible.</p>
<div id="expanding-the-regression-horizon" class="section level3">
<h3><span class="header-section-number">16.1.1</span> Expanding the Regression Horizon</h3>
<p>There are several ways in which we can enrich and extend a linear regression
model. Having said that, we will describe just a few of these ways. Trying to
cover all possible extensions would require us to write a whole separate book.</p>
<p>To make the discussion more organized, we have decided to classify the covered
approaches into two major classes that we are calling: (1) parametric models,
and (2) nonparametric models.</p>
<p>At this point, we have two magic words that deserve our attention: <em>linear</em> and
<em>(non)parametric</em>:</p>
<ul>
<li><p>When people talk about <em>linear</em> regression models, what do they exactly mean
by “linear”?</p></li>
<li><p>When people talk about <em>parametric -vs- nonparametric</em> models, what do they
mean by this? What kind of parameters are they referring to?</p></li>
</ul>
<div id="linearity" class="section level4 unnumbered">
<h4>Linearity</h4>
<p>The standard linear regression model:</p>
<p><span class="math display">\[
f(X) = b_0 + b_1 X_1 + \dots + b_p X_p
\]</span></p>
<p>is linear two modes. On one hand, it
is linear in the input variables <span class="math inline">\(X_1, \dots, X_p\)</span>. On the other hand, it is
also linear in the parameters <span class="math inline">\(b_0, b_1, \dots, b_p\)</span>. As we said before,
although a model ike this is very friendly to work with, its double linearity
is very restrictive.</p>
<p>In the regression world, the most general type of linearity is the one that
applies to the regression coefficients or parameters <span class="math inline">\(b_0, b_1, \dots, b_p\)</span>.
Here’s an example of a model that is nonlinear with respect to the predictors,
but linear with respect to the parameters:</p>
<p><span class="math display">\[
f(X) = b_0 + b_1 X_1 + b_2 X_2 + b_3 X_1^2 + b_4 X_2^2
\]</span></p>
<p>In contrast, the model below is nonlinear in both the predictors and the
parameters:</p>
<p><span class="math display">\[
f(X) = b_0 + exp(X_1^{b_1}) + \sqrt{b_2 X_2}
\]</span></p>
<p>So, when using the term “linear model”, we are referring to a model that is
linear in its coefficients or parameters, not necessarily in the input features.</p>
</div>
<div id="parametric-and-nonparametric" class="section level4 unnumbered">
<h4>Parametric and Nonparametric</h4>
<p>The word “parametric”, and its sibling “nonparametric”, are those kind of terms
commonly used in various branches of statistics. For better or worse, they form
part of those terms that people assign different meanings to. Depending on who
you talk to, some people will give you a definition of the term “nonparametric”
in the sense of distribution-free methods—or so called nonparametric statistics.
This is NOT the meaning that we use in this book for nonparametric.</p>
<p>So what do we mean by parametric and nonparametric?</p>
<p>By parametric, we refer to a functional form of <span class="math inline">\(f()\)</span> that is fully described
by a finite set of parameters, like in the standard linear model</p>
<p><span class="math display">\[
f(X) = b_0 + b_1 X_1 + \dots + b_p X_p
\]</span></p>
<p>In this book we use the notion of nonparametric models to imply a more relaxed
way to specify a function <span class="math inline">\(f()\)</span> without directly imposing a known functional
form. Somewhat contradictory, nonparametric does not necessarily mean that a
model has no parameters. As we’ll see, it turns out that nonparametric models
do have parameters (or hyperparameters).</p>
<p>A common example of a nonparametric method is <span class="math inline">\(K\)</span>-Nearest-Neighbors or <span class="math inline">\(K\)</span>-NN
for short. The functional form of <span class="math inline">\(f()\)</span> is way more relaxed, and all we do is
use an average of the response values <span class="math inline">\(y_i\)</span> for the closest <span class="math inline">\(K\)</span> points <span class="math inline">\(x_i\)</span>
to a query value <span class="math inline">\(x_0\)</span>:</p>
<p><span class="math display">\[
\hat{y}_0 = \frac{1}{K} \sum_{i \in N(x_0)} y_i
\]</span></p>
<p>where the notation <span class="math inline">\(N(x_0)\)</span> indicates the set of <span class="math inline">\(K\)</span> closest neighbors to <span class="math inline">\(x_0\)</span>.</p>
<p>Notice that <span class="math inline">\(K\)</span>-NN does not impose any functional form of how to combine the
<span class="math inline">\(X\)</span>-input feature(s). In this sense, we say that this is a nonparametric model.</p>
<p>Now that we have provide some clarifications on the meanings of terms such as
“linear”, “parametric”, and “nonparametric”, we can continue with our
introduction of ways in which we can extend linear models beyond linearity,
as well as extensions of models in a more relaxed (nonparametric) sense.</p>
</div>
</div>
</div>
<div id="transforming-features" class="section level2">
<h2><span class="header-section-number">16.2</span> Transforming Features</h2>
<p>Let us consider parametric models first. A first option to make a linear model
more sophisticated is by means of applying transformaitons to some or all of
the input features. This is not a new idea. In fact, we have alredy used this
strategy when we studied <a href="pcr">Principal Commponents Regression</a> and
<a href="pls">Partial Least Squares Regression</a>.</p>
<p>Consider a linear model that uses some type of dimension reduction approach.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-162"></span>
<img src="images/pcr/pcr-path-diag-scores.svg" alt="PCs as linear combinations of input variables" width="85%" />
<p class="caption">
Figure 16.2: PCs as linear combinations of input variables
</p>
</div>
<p>We can think of any given component <span class="math inline">\(Z_h\)</span> as a transformation applied on all
the <span class="math inline">\(X\)</span>-input variables, that is:</p>
<p><span class="math display">\[
Z_h = v_{1h} X_1 + \dots + v_{ph} X_p \quad \longrightarrow \quad Z_h = \phi_h (X_1, \dots, X_p)
\]</span></p>
<p>We an explicitly think of a function <span class="math inline">\(\phi_h : \mathbb{R}^p \rightarrow \mathbb{R}\)</span> that transforms the inputs into a new synthetic feature.
In the case of PCR and PLSR, the tranasformation functions <span class="math inline">\(\phi_h\)</span> happen to be
linear functions.</p>
<p><strong>INSERT PATH DIAGRAM</strong></p>
<p><span class="math display">\[
\phi_1 (\mathbf{x}) = \mathbf{z_1}, \phi_2 (\mathbf{x}) = \mathbf{z_2}, \dots , \phi_r (\mathbf{x}) = \mathbf{z_r} 
\]</span></p>
<p>The matrix <span class="math inline">\(\mathbf{Z}\)</span> can be represented by a matrix <span class="math inline">\(\mathbf{\Phi}\)</span></p>
<p>Then, the predicted response is given by:</p>
<p><span class="math display">\[
\mathbf{\hat{y}} = \mathbf{\Phi} (\mathbf{\Phi}^\mathsf{T} \mathbf{\Phi})^{-1} \mathbf{\Phi}^\mathsf{T} \mathbf{y}
\]</span></p>

</div>
</div>



            </section>

          </div>
        </div>
      </div>
<a href="ridge.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="classif.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["allmodelsarewrong.pdf", "allmodelsarewrong.epub"],
"toc": {
"collapse": "section"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
